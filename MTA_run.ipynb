{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T02:53:35.518061Z",
     "start_time": "2024-10-12T02:53:34.943404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "import duckdb\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import fastparquet\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ],
   "id": "eab26980e7287f7b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T02:27:27.345840Z",
     "start_time": "2024-10-12T02:27:27.323515Z"
    }
   },
   "cell_type": "code",
   "source": "con = duckdb.connect(\"subway-trips.db\")",
   "id": "cf6ec6753af42db2",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T23:13:43.893341Z",
     "start_time": "2024-10-11T23:13:43.882210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = con.sql(\"SELECT * FROM trips LIMIT 5\").df()\n",
    "\n",
    "print(df)"
   ],
   "id": "f18afaf89dfe24c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month day_of_week  hour_of_day    origin_station_complex_name  \\\n",
      "0      1      Monday            1               Canal St (A,C,E)   \n",
      "1      1      Monday            1                    65 St (M,R)   \n",
      "2      1      Monday            1                   Astor Pl (6)   \n",
      "3      1      Monday            1  161 St-Yankee Stadium (B,D,4)   \n",
      "4      1      Monday            1       Myrtle-Wyckoff Avs (L,M)   \n",
      "\n",
      "  destination_station_complex_name  estimated_average_ridership  \n",
      "0         Canal St (J,N,Q,R,W,Z,6)                       0.8476  \n",
      "1                Junction Blvd (7)                       0.2000  \n",
      "2       Clinton-Washington Avs (G)                       0.2400  \n",
      "3                     Bay Pkwy (N)                       0.2000  \n",
      "4                    Forest Av (M)                       0.6118  \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T23:09:01.897648Z",
     "start_time": "2024-10-11T23:09:01.893200Z"
    }
   },
   "cell_type": "code",
   "source": "columns_to_drop = ['year', 'timestamp','origin_station_complex_id', 'destination_station_complex_id', 'origin_latitude', 'destination_latitude', 'origin_longitude', 'destination_longitude', 'origin_point', 'destination_point' ]  # Replace with your actual column names",
   "id": "196e6d50ea5a1835",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T23:09:58.765165Z",
     "start_time": "2024-10-11T23:09:58.630731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for column in columns_to_drop:\n",
    "    con.execute(f\"ALTER TABLE trips DROP COLUMN {column};\")\n",
    "    print(f\"Column {column} dropped\")"
   ],
   "id": "198d4b44ff21cfe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column year dropped\n",
      "Column timestamp dropped\n",
      "Column origin_station_complex_id dropped\n",
      "Column destination_station_complex_id dropped\n",
      "Column origin_latitude dropped\n",
      "Column destination_latitude dropped\n",
      "Column origin_longitude dropped\n",
      "Column destination_longitude dropped\n",
      "Column origin_point dropped\n",
      "Column destination_point dropped\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T23:10:13.547536Z",
     "start_time": "2024-10-11T23:10:13.540349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = con.execute(\"SELECT * FROM trips LIMIT 5;\").fetchdf()\n",
    "print(result)"
   ],
   "id": "ca7c8e81e16dafcd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month day_of_week  hour_of_day    origin_station_complex_name  \\\n",
      "0      1      Monday            1               Canal St (A,C,E)   \n",
      "1      1      Monday            1                    65 St (M,R)   \n",
      "2      1      Monday            1                   Astor Pl (6)   \n",
      "3      1      Monday            1  161 St-Yankee Stadium (B,D,4)   \n",
      "4      1      Monday            1       Myrtle-Wyckoff Avs (L,M)   \n",
      "\n",
      "  destination_station_complex_name  estimated_average_ridership  \n",
      "0         Canal St (J,N,Q,R,W,Z,6)                       0.8476  \n",
      "1                Junction Blvd (7)                       0.2000  \n",
      "2       Clinton-Washington Avs (G)                       0.2400  \n",
      "3                     Bay Pkwy (N)                       0.2000  \n",
      "4                    Forest Av (M)                       0.6118  \n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T02:35:31.053293Z",
     "start_time": "2024-10-12T02:33:06.737788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert to parquet\n",
    "\n",
    "# Specify the output Parquet file\n",
    "parquet_file = 'subway-trips.parquet'\n",
    "\n",
    "# Define the chunk size (number of rows per chunk)\n",
    "chunk_size = 1000000  # Adjust based on your memory capacity and requirements\n",
    "\n",
    "parquet_writer = None\n",
    "\n",
    "# Start writing to the Parquet file\n",
    "with open(parquet_file, 'wb') as f:\n",
    "    # Use DuckDB's INSERT INTO syntax to write data in chunks\n",
    "    # This will create the Parquet file in chunks, preventing memory overflow\n",
    "    offset = 0\n",
    "    while True:\n",
    "        # Fetch the next chunk of data from the trips table\n",
    "        start_time = time.time()\n",
    "        df_chunk = con.execute(f\"SELECT * FROM trips LIMIT {chunk_size} OFFSET {offset}\").fetchdf()\n",
    "        rows = df_chunk.shape[0]\n",
    "\n",
    "        # Write the chunk to the Parquet file\n",
    "        table = pa.Table.from_pandas(df_chunk)\n",
    "        \n",
    "        # Write the first chunk, then append subsequent chunks\n",
    "        if parquet_writer is None:\n",
    "            # Initialize the writer with the schema of the first chunk\n",
    "            parquet_writer = pq.ParquetWriter(parquet_file, table.schema, compression='gzip')\n",
    "        \n",
    "        # Write the table to the Parquet file\n",
    "        parquet_writer.write_table(table)\n",
    "        \n",
    "        if rows < chunk_size:\n",
    "            print(f\"Finished processing all data.\")\n",
    "            break\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Processed {offset + rows} rows. Elapsed time is {elapsed_time:.4f} seconds\")\n",
    "\n",
    "        # Move the offset forward\n",
    "        offset += chunk_size\n",
    "        \n",
    "    # Close the ParquetWriter\n",
    "    if parquet_writer:\n",
    "        parquet_writer.close()\n",
    "\n"
   ],
   "id": "97f3bbb716cb9f5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000000 rows. Elapsed time is 1.5495 seconds\n",
      "Processed 2000000 rows. Elapsed time is 1.4404 seconds\n",
      "Processed 3000000 rows. Elapsed time is 0.9691 seconds\n",
      "Processed 4000000 rows. Elapsed time is 1.0603 seconds\n",
      "Processed 5000000 rows. Elapsed time is 0.9530 seconds\n",
      "Processed 6000000 rows. Elapsed time is 0.9802 seconds\n",
      "Processed 7000000 rows. Elapsed time is 0.9654 seconds\n",
      "Processed 8000000 rows. Elapsed time is 0.9686 seconds\n",
      "Processed 9000000 rows. Elapsed time is 0.9228 seconds\n",
      "Processed 10000000 rows. Elapsed time is 1.0160 seconds\n",
      "Processed 11000000 rows. Elapsed time is 1.0334 seconds\n",
      "Processed 12000000 rows. Elapsed time is 1.0170 seconds\n",
      "Processed 13000000 rows. Elapsed time is 0.9943 seconds\n",
      "Processed 14000000 rows. Elapsed time is 1.0084 seconds\n",
      "Processed 15000000 rows. Elapsed time is 1.0088 seconds\n",
      "Processed 16000000 rows. Elapsed time is 0.9928 seconds\n",
      "Processed 17000000 rows. Elapsed time is 1.0058 seconds\n",
      "Processed 18000000 rows. Elapsed time is 1.0533 seconds\n",
      "Processed 19000000 rows. Elapsed time is 1.0421 seconds\n",
      "Processed 20000000 rows. Elapsed time is 1.0396 seconds\n",
      "Processed 21000000 rows. Elapsed time is 1.0188 seconds\n",
      "Processed 22000000 rows. Elapsed time is 1.0409 seconds\n",
      "Processed 23000000 rows. Elapsed time is 1.0534 seconds\n",
      "Processed 24000000 rows. Elapsed time is 0.9770 seconds\n",
      "Processed 25000000 rows. Elapsed time is 1.0299 seconds\n",
      "Processed 26000000 rows. Elapsed time is 1.0208 seconds\n",
      "Processed 27000000 rows. Elapsed time is 1.0120 seconds\n",
      "Processed 28000000 rows. Elapsed time is 1.0109 seconds\n",
      "Processed 29000000 rows. Elapsed time is 1.0273 seconds\n",
      "Processed 30000000 rows. Elapsed time is 1.0847 seconds\n",
      "Processed 31000000 rows. Elapsed time is 1.1219 seconds\n",
      "Processed 32000000 rows. Elapsed time is 1.0798 seconds\n",
      "Processed 33000000 rows. Elapsed time is 1.0636 seconds\n",
      "Processed 34000000 rows. Elapsed time is 1.1055 seconds\n",
      "Processed 35000000 rows. Elapsed time is 1.0094 seconds\n",
      "Processed 36000000 rows. Elapsed time is 1.2254 seconds\n",
      "Processed 37000000 rows. Elapsed time is 1.3657 seconds\n",
      "Processed 38000000 rows. Elapsed time is 1.1602 seconds\n",
      "Processed 39000000 rows. Elapsed time is 1.1373 seconds\n",
      "Processed 40000000 rows. Elapsed time is 1.2413 seconds\n",
      "Processed 41000000 rows. Elapsed time is 1.6453 seconds\n",
      "Processed 42000000 rows. Elapsed time is 1.8559 seconds\n",
      "Processed 43000000 rows. Elapsed time is 1.7905 seconds\n",
      "Processed 44000000 rows. Elapsed time is 1.5851 seconds\n",
      "Processed 45000000 rows. Elapsed time is 1.6039 seconds\n",
      "Processed 46000000 rows. Elapsed time is 2.6444 seconds\n",
      "Processed 47000000 rows. Elapsed time is 1.8771 seconds\n",
      "Processed 48000000 rows. Elapsed time is 2.0106 seconds\n",
      "Processed 49000000 rows. Elapsed time is 2.0920 seconds\n",
      "Processed 50000000 rows. Elapsed time is 1.8400 seconds\n",
      "Processed 51000000 rows. Elapsed time is 1.4283 seconds\n",
      "Processed 52000000 rows. Elapsed time is 1.3060 seconds\n",
      "Processed 53000000 rows. Elapsed time is 1.2634 seconds\n",
      "Processed 54000000 rows. Elapsed time is 1.0747 seconds\n",
      "Processed 55000000 rows. Elapsed time is 1.0419 seconds\n",
      "Processed 56000000 rows. Elapsed time is 1.1103 seconds\n",
      "Processed 57000000 rows. Elapsed time is 1.2522 seconds\n",
      "Processed 58000000 rows. Elapsed time is 1.2390 seconds\n",
      "Processed 59000000 rows. Elapsed time is 1.1366 seconds\n",
      "Processed 60000000 rows. Elapsed time is 1.1865 seconds\n",
      "Processed 61000000 rows. Elapsed time is 1.1136 seconds\n",
      "Processed 62000000 rows. Elapsed time is 1.3937 seconds\n",
      "Processed 63000000 rows. Elapsed time is 1.1875 seconds\n",
      "Processed 64000000 rows. Elapsed time is 1.1442 seconds\n",
      "Processed 65000000 rows. Elapsed time is 1.1803 seconds\n",
      "Processed 66000000 rows. Elapsed time is 1.1853 seconds\n",
      "Processed 67000000 rows. Elapsed time is 1.2234 seconds\n",
      "Processed 68000000 rows. Elapsed time is 1.2662 seconds\n",
      "Processed 69000000 rows. Elapsed time is 1.1394 seconds\n",
      "Processed 70000000 rows. Elapsed time is 1.1591 seconds\n",
      "Processed 71000000 rows. Elapsed time is 1.1701 seconds\n",
      "Processed 72000000 rows. Elapsed time is 1.2206 seconds\n",
      "Processed 73000000 rows. Elapsed time is 1.2668 seconds\n",
      "Processed 74000000 rows. Elapsed time is 1.2632 seconds\n",
      "Processed 75000000 rows. Elapsed time is 1.2433 seconds\n",
      "Processed 76000000 rows. Elapsed time is 1.2502 seconds\n",
      "Processed 77000000 rows. Elapsed time is 1.2577 seconds\n",
      "Processed 78000000 rows. Elapsed time is 1.1369 seconds\n",
      "Processed 79000000 rows. Elapsed time is 1.2888 seconds\n",
      "Processed 80000000 rows. Elapsed time is 1.3204 seconds\n",
      "Processed 81000000 rows. Elapsed time is 1.3052 seconds\n",
      "Processed 82000000 rows. Elapsed time is 1.2417 seconds\n",
      "Processed 83000000 rows. Elapsed time is 1.1904 seconds\n",
      "Processed 84000000 rows. Elapsed time is 1.2442 seconds\n",
      "Processed 85000000 rows. Elapsed time is 1.2110 seconds\n",
      "Processed 86000000 rows. Elapsed time is 1.1816 seconds\n",
      "Processed 87000000 rows. Elapsed time is 1.2780 seconds\n",
      "Processed 88000000 rows. Elapsed time is 1.2177 seconds\n",
      "Processed 89000000 rows. Elapsed time is 1.2533 seconds\n",
      "Processed 90000000 rows. Elapsed time is 1.1977 seconds\n",
      "Processed 91000000 rows. Elapsed time is 1.2299 seconds\n",
      "Processed 92000000 rows. Elapsed time is 1.2198 seconds\n",
      "Processed 93000000 rows. Elapsed time is 1.1899 seconds\n",
      "Processed 94000000 rows. Elapsed time is 1.2928 seconds\n",
      "Processed 95000000 rows. Elapsed time is 1.2755 seconds\n",
      "Processed 96000000 rows. Elapsed time is 1.2466 seconds\n",
      "Processed 97000000 rows. Elapsed time is 1.3332 seconds\n",
      "Processed 98000000 rows. Elapsed time is 1.4028 seconds\n",
      "Processed 99000000 rows. Elapsed time is 1.3092 seconds\n",
      "Processed 100000000 rows. Elapsed time is 1.2708 seconds\n",
      "Processed 101000000 rows. Elapsed time is 1.2777 seconds\n",
      "Processed 102000000 rows. Elapsed time is 1.2706 seconds\n",
      "Processed 103000000 rows. Elapsed time is 1.3438 seconds\n",
      "Processed 104000000 rows. Elapsed time is 1.2067 seconds\n",
      "Processed 105000000 rows. Elapsed time is 1.3259 seconds\n",
      "Processed 106000000 rows. Elapsed time is 1.3031 seconds\n",
      "Processed 107000000 rows. Elapsed time is 1.2905 seconds\n",
      "Processed 108000000 rows. Elapsed time is 1.3330 seconds\n",
      "Processed 109000000 rows. Elapsed time is 1.2933 seconds\n",
      "Processed 110000000 rows. Elapsed time is 1.4111 seconds\n",
      "Processed 111000000 rows. Elapsed time is 1.3712 seconds\n",
      "Processed 112000000 rows. Elapsed time is 1.3486 seconds\n",
      "Processed 113000000 rows. Elapsed time is 1.3679 seconds\n",
      "Processed 114000000 rows. Elapsed time is 1.3737 seconds\n",
      "Processed 115000000 rows. Elapsed time is 1.3539 seconds\n",
      "Finished processing all data.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:03:27.981974Z",
     "start_time": "2024-10-12T05:03:27.975737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_size = os.path.getsize('subway-trips.parquet')\n",
    "\n",
    "# Convert the size to megabytes (MB) for easier readability\n",
    "file_size_mb = file_size / (1024 * 1024)\n",
    "\n",
    "print(f\"Size of subway-trips.parquet: {file_size_mb:.2f} MB\")\n",
    "\n",
    "# Convert the size to gigabytes (GB)\n",
    "file_size_gb = file_size / (1024 ** 3)  \n",
    "\n",
    "print(f\"Size of subway-trips.parquet: {file_size_gb:.2f} GB\")"
   ],
   "id": "2bce52f1c31366b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of subway-trips.parquet: 499.72 MB\n",
      "Size of subway-trips.parquet: 0.49 GB\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T02:55:58.155317Z",
     "start_time": "2024-10-12T02:55:58.141585Z"
    }
   },
   "cell_type": "code",
   "source": "con = duckdb.connect()",
   "id": "de809ca02b4d0ebb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T02:53:45.242007Z",
     "start_time": "2024-10-12T02:53:45.203198Z"
    }
   },
   "cell_type": "code",
   "source": "con.sql(f\"SELECT COUNT(*) FROM 'subway-trips.parquet'\").show()",
   "id": "813991ab57917ac0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┐\n",
      "│ count_star() │\n",
      "│    int64     │\n",
      "├──────────────┤\n",
      "│    115731896 │\n",
      "└──────────────┘\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T02:56:22.106963Z",
     "start_time": "2024-10-12T02:56:22.087499Z"
    }
   },
   "cell_type": "code",
   "source": "con2 = duckdb.connect(\"subway-trips.db\")",
   "id": "b697176d79f49cd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T02:56:24.890422Z",
     "start_time": "2024-10-12T02:56:24.857063Z"
    }
   },
   "cell_type": "code",
   "source": "con2.sql(f\"SELECT COUNT(*) FROM trips\").show()",
   "id": "5bcad01330360310",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┐\n",
      "│ count_star() │\n",
      "│    int64     │\n",
      "├──────────────┤\n",
      "│    115731896 │\n",
      "└──────────────┘\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:40:05.842776Z",
     "start_time": "2024-10-12T04:40:05.838704Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 13,
   "source": [
    "# Close the database connection\n",
    "con.close()"
   ],
   "id": "38968632657e6621"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:40:00.987692Z",
     "start_time": "2024-10-12T04:40:00.981043Z"
    }
   },
   "cell_type": "code",
   "source": "con2.close()",
   "id": "99e60f9932e1d3fd",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
